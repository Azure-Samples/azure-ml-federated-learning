{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the experimental FL Scatter-Gather DSL Node to submit the CCFRAUD example "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create AML resources by following this tutorial: \n",
    "https://github.com/Azure-Samples/azure-ml-federated-learning/blob/main/docs/quickstart.md"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"AZURE_ML_CLI_PRIVATE_FEATURES_ENABLED\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import string\n",
    "import datetime\n",
    "import webbrowser\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Azure ML sdk v2 imports\n",
    "import azure\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient, Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml import load_component\n",
    "\n",
    "# to handle yaml config easily\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load components"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCFRAUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_CONFIG = OmegaConf.load(\"./ccfraud/config_fl_sdk.yaml\")\n",
    "# path to the components\n",
    "COMPONENTS_FOLDER = os.path.join(\n",
    "    \"./\", \"..\", \"components\", \"CCFRAUD\"\n",
    ")\n",
    "\n",
    "# path to the shared components\n",
    "SHARED_COMPONENTS_FOLDER = os.path.join(\n",
    "    \"./\", \"..\", \"components\", \"utils\"\n",
    ")\n",
    "\n",
    "\n",
    "preprocessing_component = load_component(\n",
    "    source=os.path.join(COMPONENTS_FOLDER, \"preprocessing\", \"spec.yaml\")\n",
    ")\n",
    "\n",
    "training_component = load_component(\n",
    "    source=os.path.join(COMPONENTS_FOLDER, \"traininsilo\", \"spec.yaml\")\n",
    ")\n",
    "\n",
    "aggregate_component = load_component(\n",
    "    source=os.path.join(SHARED_COMPONENTS_FOLDER, \"aggregatemodelweights_mltable\", \"spec.yaml\")\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create ML client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER TODO: fill in these values if you wish to produce a client handle without going through online authentication.\n",
    "subscription_id = 'XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX'\n",
    "resource_group = \"XXXXXXX\"\n",
    "workspace = \"XXXXXXX\"\n",
    "\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "if subscription_id is not None and resource_group is not None and workspace is not None:\n",
    "    ml_client = MLClient(InteractiveBrowserCredential(), subscription_id, resource_group, workspace)\n",
    "    print(\"Client created from user-provided values.\")\n",
    "else:\n",
    "    print(\"Client Unchanged.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Federated Learning Silos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.entities._assets.federated_learning_silo import FederatedLearningSilo\n",
    "\n",
    "silo_list = [\n",
    "    FederatedLearningSilo(\n",
    "        compute=silo_config[\"computes\"][0],\n",
    "        datastore=silo_config[\"datastore\"],\n",
    "        inputs= {\n",
    "            \"silo_name\": dict(silo_config)[\"name\"],\n",
    "            \"raw_train_data\": Input(**dict(silo_config)[\"training_data\"]),\n",
    "            \"raw_test_data\": Input(**dict(silo_config)[\"testing_data\"]),\n",
    "            \n",
    "        },\n",
    "    )\n",
    "    for silo_config in YAML_CONFIG.federated_learning.silos\n",
    "]\n",
    "print(\"Silo list created\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silo_to_aggregation_argument_map = {\"model\" : \"from_silo_input\"}\n",
    "aggregation_to_silo_argument_map = {\"aggregated_output\" : \"checkpoint\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create kwarg input maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silo_kwargs = dict(YAML_CONFIG.training_parameters)\n",
    "agg_kwargs = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Silo subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    name=\"Silo FL Subgraph\",\n",
    "    description=\"It includes all steps that needs to be executing in silo\",\n",
    ")\n",
    "def silo_scatter_subgraph(\n",
    "    # user defined inputs\n",
    "    raw_train_data: Input,\n",
    "    raw_test_data: Input,\n",
    "    checkpoint: Input(optional=True),\n",
    "    silo_name: str,\n",
    "    # user defined training arguments\n",
    "    model_name: str = 'SimpleLinear',\n",
    "    lr: float = 0.01,\n",
    "    epochs: int = 3,\n",
    "    batch_size: int = 64,\n",
    "    dp: bool = False,\n",
    "    dp_target_epsilon: float = 50.0,\n",
    "    dp_target_delta: float = 1e-5,\n",
    "    dp_max_grad_norm: float = 1.0,\n",
    ") -> dict:\n",
    "    \"\"\"Create scatter/silo subgraph.\n",
    "\n",
    "    Args:\n",
    "        raw_train_data (Input): raw train data\n",
    "        raw_test_data (Input): raw test data\n",
    "        checkpoint (Input): if not None, the checkpoint obtained from previous iteration\n",
    "        scatter_compute1 (str): Silo compute1 name\n",
    "        scatter_compute2 (str): Silo compute2 name\n",
    "        iteration_num (int): Iteration number\n",
    "        lr (float, optional): Learning rate. Defaults to 0.01.\n",
    "        epochs (int, optional): Number of epochs. Defaults to 3.\n",
    "        batch_size (int, optional): Batch size. Defaults to 64.\n",
    "        dp (bool, optional): Differential Privacy\n",
    "        dp_target_epsilon (float, optional): DP target epsilon\n",
    "        dp_target_delta (float, optional): DP target delta\n",
    "        dp_max_grad_norm (float, optional): DP max gradient norm\n",
    "        num_of_iterations (int, optional): Total number of iterations\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Outputs]: a map of the outputs\n",
    "    \"\"\"\n",
    "    # we're using our own preprocessing component\n",
    "    silo_pre_processing_step = preprocessing_component(\n",
    "        raw_training_data=raw_train_data,\n",
    "        raw_testing_data=raw_test_data,\n",
    "        metrics_prefix=silo_name,\n",
    "    )\n",
    "    silo_pre_processing_step.environment_variables = {\n",
    "        \"CONFIDENTIALITY_DISABLE\": \"True\",\n",
    "    }\n",
    "    \n",
    "    # # Assigning the silo's first compute to the preprocessing component\n",
    "    # silo_pre_processing_step.compute = silo_compute1\n",
    "\n",
    "    # we're using our own training component\n",
    "    silo_training_step = training_component(\n",
    "        # with the train_data from the pre_processing step\n",
    "        train_data=silo_pre_processing_step.outputs.processed_train_data,\n",
    "        # with the test_data from the pre_processing step\n",
    "        test_data=silo_pre_processing_step.outputs.processed_test_data,\n",
    "        # and the checkpoint from previous iteration (or None if iteration == 1)\n",
    "        checkpoint=checkpoint,\n",
    "        # Learning rate for local training\n",
    "        lr=lr,\n",
    "        # Number of epochs\n",
    "        epochs=epochs,\n",
    "        # Dataloader batch size\n",
    "        batch_size=batch_size,\n",
    "        # Differential Privacy\n",
    "        dp=dp,\n",
    "        model_name=model_name,\n",
    "        # DP target epsilon\n",
    "        dp_target_epsilon=dp_target_epsilon,\n",
    "        # DP target delta\n",
    "        dp_target_delta=dp_target_delta,\n",
    "        # DP max gradient norm\n",
    "        dp_max_grad_norm=dp_max_grad_norm,\n",
    "        # Silo name/identifier\n",
    "        metrics_prefix=silo_name,\n",
    "    )\n",
    "    silo_training_step.environment_variables = {\n",
    "        \"CONFIDENTIALITY_DISABLE\": \"True\",\n",
    "    }\n",
    "\n",
    "    # # Assigning the silo's second compute to the training component\n",
    "    # silo_training_step.compute = silo_compute1\n",
    "\n",
    "    # IMPORTANT: we will assume that any output provided here can be exfiltrated into the orchestrator/gather\n",
    "    return {\n",
    "        # NOTE: the key you use is custom\n",
    "        # a map function scatter_to_gather_map needs to be provided\n",
    "        # to map the name here to the expected input from gather\n",
    "        \"model\": silo_training_step.outputs.model\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together - Creating a Pipeline with an FLCG Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "import azure.ai.ml.dsl._fl_scatter_gather_node as fl\n",
    "\n",
    "fl_node = fl.fl_scatter_gather(\n",
    "    silo_configs=silo_list,\n",
    "    silo_component=silo_scatter_subgraph,\n",
    "    aggregation_component=aggregate_component,\n",
    "    aggregation_compute=YAML_CONFIG.federated_learning.orchestrator.compute,\n",
    "    aggregation_datastore=YAML_CONFIG.federated_learning.orchestrator.datastore,\n",
    "    shared_silo_kwargs=silo_kwargs,\n",
    "    aggregation_kwargs=agg_kwargs,\n",
    "    silo_to_aggregation_argument_map=silo_to_aggregation_argument_map,\n",
    "    aggregation_to_silo_argument_map=aggregation_to_silo_argument_map,\n",
    "    max_iterations=YAML_CONFIG.federated_learning.num_of_iterations, \n",
    ")\n",
    "\n",
    "fl_pipeline_job = ml_client.jobs.create_or_update(fl_node.scatter_gather_graph, experiment_name=\"fl_sdk_ccfraud\")\n",
    "fl_pipeline_job"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_sdk_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fd1569a76b7ca3eba0da9e0ecbed98cdf9c274b2525be53134564ec5983f107"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
