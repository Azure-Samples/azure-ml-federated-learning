# EXAMPLE CONFIG FILE

# This file is intended to help contain all the parameters required
# to orchestrate our sample federated learning experiments.
# It is by no means necessary to run an FL experiment, just helpful.
# See submit.py for details on how to consume this file in python.

# This should work out of the box when running an experiment
# on one of our sandbox environments.

# Follow the instructions in the comments to adapt to your settings.

# References to Azure ML workspace (use cli args to override)
aml:
  # subscription_id: "<SUBSCRIPTION_ID>"
  # resource_group_name: "<RESOURCE_GROUP>"
  # workspace_name: "<AML_WORKSPACE_NAME>"

# federated learning parameters
orchestrator:
  # name of compute for orchestrator
  compute: "orchestrator-01"
  # name of datastore for orchestrator (saving model weights + aggregate)
  datastore: "datastore_orchestrator"


# strategy represents how the "in silo" part of the graph is scattered
strategy: # NOTE: same terminology as in devops/github matrix+strategy
  horizontal: # we're using the same training in each silo
    - compute: silo0-01 # name of the compute for silo X
      datastore: datastore_silo0 # name of the datastore for silo X
      # training inputs are specified below
      # NOTE: in this demo, we're using public data from a url instead
      inputs:
        name: silo0
        training_data:
          type: uri_folder
          mode: download
          path: azureml://datastores/datastore_silo0/paths/federated_learning/ner/raw_train_data/
        testing_data:
          type: uri_folder
          mode: download
          path: azureml://datastores/datastore_silo0/paths/federated_learning/ner/raw_test_data/

    - compute: silo1-01 # we are repeating over the same config for silo 2
      datastore: datastore_silo1
      inputs:
        name: silo1
        silo_data:
          type: uri_file
          mode: 'download'
          path: azureml://datastores/datastore_silo1/paths/federated_learning/pneumonia
        training_data:
          type: uri_folder
          mode: download
          path: azureml://datastores/datastore_silo1/paths/federated_learning/ner/raw_train_data/
        testing_data:
          type: uri_folder
          mode: download
          path: azureml://datastores/datastore_silo1/paths/federated_learning/ner/raw_test_data/

    - compute: silo2-01 # we are repeating over the same config for silo 3
      datastore: datastore_silo2
      inputs:
        name: silo2
        silo_data:
          type: uri_file
          mode: 'download'
          path: azureml://datastores/datastore_silo2/paths/federated_learning/pneumonia
        training_data:
          type: uri_folder
          mode: download
          path: azureml://datastores/datastore_silo2/paths/federated_learning/ner/raw_train_data/
        testing_data:
          type: uri_folder
          mode: download
          path: azureml://datastores/datastore_silo2/paths/federated_learning/ner/raw_test_data/

iterations: 2

# Training parameters
inputs:
  
  # then typical training parameters
  tokenizer_name: "bert-base-cased" # Tokenizer name
  model_name: "bert-base-cased" # Pre-trained Model name
  epochs: 3 # number of epochs per iteration (in-silo training) 
  lr: 0.01 # learning rate
  batch_size: 16 # batch size

  # Differential privacy
  dp: false # Flag to enable/disable differential privacy
  dp_target_epsilon: 50.0 # Smaller epsilon means more privacy, more noise (it depends on the size of the training dataset. For more info, please visit https://opacus.ai/docs/faq#what-does-epsilon11-really-mean-how-about-delta )
  dp_target_delta: 1e-5 # The target δ of the (ϵ,δ)-differential privacy guarantee. Generally, it should be set to be less than the inverse of the size of the training dataset. 
  dp_max_grad_norm: 1.0 # Clip per-sample gradients to this norm (DP)

  # if you want to use the privacy_engine.make_private method, please set the value of dp_noise_multiplier parameter
  # dp_noise_multiplier: 1.0 # Noise multiplier - to add noise to gradients (DP)
