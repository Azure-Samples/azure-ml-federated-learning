{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the experimental FL Scatter-Gather DSL Node to submit the HELLOWORLD example "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create AML resources by following this tutorial: \n",
    "https://github.com/Azure-Samples/azure-ml-federated-learning/blob/main/docs/quickstart.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"AZURE_ML_CLI_PRIVATE_FEATURES_ENABLED\"] = \"True\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import string\n",
    "import datetime\n",
    "import webbrowser\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Azure ML sdk v2 imports\n",
    "import azure\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient, Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml import load_component\n",
    "\n",
    "# to handle yaml config easily\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_CONFIG = OmegaConf.load(\"config.yaml\")\n",
    "# path to the components\n",
    "COMPONENTS_FOLDER = os.path.join(\n",
    "    \"./\", \"..\", \"..\", \"components\", \"MNIST\"\n",
    ")\n",
    "\n",
    "# path to the shared components\n",
    "SHARED_COMPONENTS_FOLDER = os.path.join(\n",
    "    \"./\", \"..\", \"..\", \"components\", \"utils\"\n",
    ")\n",
    "\n",
    "\n",
    "preprocessing_component = load_component(\n",
    "    source=os.path.join(COMPONENTS_FOLDER, \"preprocessing\", \"spec.yaml\")\n",
    ")\n",
    "\n",
    "training_component = load_component(\n",
    "    source=os.path.join(COMPONENTS_FOLDER, \"traininsilo\", \"spec.yaml\")\n",
    ")\n",
    "\n",
    "aggregate_component = load_component(\n",
    "    source=os.path.join(SHARED_COMPONENTS_FOLDER, \"aggregatemodelweights\", \"spec.yaml\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create ML client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client created from user-provided values.\n"
     ]
    }
   ],
   "source": [
    "# USER TODO: fill in these values if you wish to produce a client handle without going through online authentication.\n",
    "subscription_id = '48bbc269-ce89-4f6f-9a12-c6f91fcb772d'\n",
    "resource_group = 'amitgarg-fldev-rg'\n",
    "workspace = 'aml-vnetdowhiletest'\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "if subscription_id is not None and resource_group is not None and workspace is not None:\n",
    "    ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)\n",
    "    print(\"Client created from user-provided values.\")\n",
    "else:\n",
    "    print(\"Client Unchanged.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Federated Learning Silos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silo list created\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.entities._assets.federated_learning_silo import FederatedLearningSilo\n",
    "\n",
    "silo_list = [\n",
    "    FederatedLearningSilo(\n",
    "        compute=silo_config[\"compute\"],\n",
    "        datastore=silo_config[\"datastore\"],\n",
    "        inputs= {\n",
    "            \"silo_name\": dict(silo_config[\"inputs\"])[\"name\"],\n",
    "            \"raw_train_data\": Input(**dict(silo_config[\"inputs\"])[\"raw_training_data\"]),\n",
    "            \"raw_test_data\": Input(**dict(silo_config[\"inputs\"])[\"raw_testing_data\"]),\n",
    "        },\n",
    "    )\n",
    "    for silo_config in YAML_CONFIG.strategy.horizontal\n",
    "]\n",
    "print(\"Silo list created\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Argument Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "silo_to_aggregation_argument_map = {\"model\" : \"from_silo_input\"}\n",
    "aggregation_to_silo_argument_map = {\"aggregated_output\" : \"checkpoint\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create kwarg input maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "silo_kwargs = dict(YAML_CONFIG.inputs)\n",
    "agg_kwargs = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Silo subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    name=\"Silo Federated Learning Subgraph\",\n",
    "    description=\"It includes all steps that needs to be executing in silo\",\n",
    ")\n",
    "def silo_scatter_subgraph(\n",
    "    # user defined inputs\n",
    "    raw_train_data: Input,\n",
    "    raw_test_data: Input,\n",
    "    checkpoint: Input(optional=True),\n",
    "    silo_name: str,\n",
    "    # user defined training arguments\n",
    "    lr: float = 0.01,\n",
    "    epochs: int = 3,\n",
    "    batch_size: int = 64,\n",
    "    dp: bool = False,\n",
    "    dp_target_epsilon: float = 50.0,\n",
    "    dp_target_delta: float = 1e-5,\n",
    "    dp_max_grad_norm: float = 1.0,\n",
    ") -> dict:\n",
    "    \"\"\"Create scatter/silo subgraph.\n",
    "\n",
    "    Args:\n",
    "        raw_train_data (Input): raw train data\n",
    "        raw_test_data (Input): raw test data\n",
    "        checkpoint (Input): if not None, the checkpoint obtained from previous iteration\n",
    "        scatter_compute1 (str): Silo compute1 name\n",
    "        scatter_compute2 (str): Silo compute2 name\n",
    "        iteration_num (int): Iteration number\n",
    "        lr (float, optional): Learning rate. Defaults to 0.01.\n",
    "        epochs (int, optional): Number of epochs. Defaults to 3.\n",
    "        batch_size (int, optional): Batch size. Defaults to 64.\n",
    "        dp (bool, optional): Differential Privacy\n",
    "        dp_target_epsilon (float, optional): DP target epsilon\n",
    "        dp_target_delta (float, optional): DP target delta\n",
    "        dp_max_grad_norm (float, optional): DP max gradient norm\n",
    "        num_of_iterations (int, optional): Total number of iterations\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Outputs]: a map of the outputs\n",
    "    \"\"\"\n",
    "    # we're using our own preprocessing component\n",
    "    silo_pre_processing_step = preprocessing_component(\n",
    "        # this consumes whatever user defined inputs\n",
    "        raw_training_data=raw_train_data,\n",
    "        raw_testing_data=raw_test_data,\n",
    "        # here we're using the name of the silo compute as a metrics prefix\n",
    "        metrics_prefix=silo_name,\n",
    "    )\n",
    "\n",
    "    # # Assigning the silo's first compute to the preprocessing component\n",
    "    # silo_pre_processing_step.compute = silo_compute1\n",
    "\n",
    "    # we're using our own training component\n",
    "    silo_training_step = training_component(\n",
    "        # with the train_data from the pre_processing step\n",
    "        train_data=silo_pre_processing_step.outputs.processed_train_data,\n",
    "        # with the test_data from the pre_processing step\n",
    "        test_data=silo_pre_processing_step.outputs.processed_test_data,\n",
    "        # and the checkpoint from previous iteration (or None if iteration == 1)\n",
    "        checkpoint=checkpoint,\n",
    "        # Learning rate for local training\n",
    "        lr=lr,\n",
    "        # Number of epochs\n",
    "        epochs=epochs,\n",
    "        # Dataloader batch size\n",
    "        batch_size=batch_size,\n",
    "        # Differential Privacy\n",
    "        dp=dp,\n",
    "        # DP target epsilon\n",
    "        dp_target_epsilon=dp_target_epsilon,\n",
    "        # DP target delta\n",
    "        dp_target_delta=dp_target_delta,\n",
    "        # DP max gradient norm\n",
    "        dp_max_grad_norm=dp_max_grad_norm,\n",
    "        # Silo name/identifier\n",
    "        metrics_prefix=silo_name,\n",
    "    )\n",
    "\n",
    "    # # Assigning the silo's second compute to the training component\n",
    "    # silo_training_step.compute = silo_compute1\n",
    "\n",
    "    # IMPORTANT: we will assume that any output provided here can be exfiltrated into the orchestrator/gather\n",
    "    return {\n",
    "        # NOTE: the key you use is custom\n",
    "        # a map function scatter_to_gather_map needs to be provided\n",
    "        # to map the name here to the expected input from gather\n",
    "        \"model\": silo_training_step.outputs.model\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together - Creating a Pipeline with an FLCG Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Method fl_scatter_gather: This is an experimental method, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading aggregatemodelweights (0.01 MBs): 100%|##########| 10413/10413 [00:00<00:00, 23222.64it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>example_fl_pipeline</td><td>clever_atemoya_nd1q37kc0b</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/clever_atemoya_nd1q37kc0b?wsid=/subscriptions/48bbc269-ce89-4f6f-9a12-c6f91fcb772d/resourcegroups/thopo-owner-fldev-rg/workspaces/aml-thopo-fl40&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {}, 'outputs': {'aggregated_output': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x00000243139762D0>}, 'jobs': {}, 'component': PipelineComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'name': 'azureml_anonymous', 'description': '\\n            Creates a scatter-gather graph by executing the scatter_gather_iteration_body\\n            function in a do-while loop. The loop terminates when the user-supplied\\n            termination condition is met.\\n            ', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\Amit Garg\\\\OneDrive - Microsoft\\\\Documents\\\\azure-samples-main-repo\\\\azure-ml-federated-learning\\\\examples\\\\pipelines\\\\fl_cross_silo_scatter_gather', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000024313974550>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'Scatter gather graph', 'is_deterministic': None, 'inputs': {}, 'outputs': {'aggregated_output': {}}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {'scatter_gather_body': Pipeline({'init': False, 'type': 'pipeline', 'status': None, 'log_files': None, 'name': 'scatter_gather_body', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\Amit Garg\\\\OneDrive - Microsoft\\\\Documents\\\\azure-samples-main-repo\\\\azure-ml-federated-learning\\\\examples\\\\pipelines\\\\fl_cross_silo_scatter_gather', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000024313973410>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'dp': 'False', 'dp_target_epsilon': '50.0', 'dp_target_delta': '1e-05', 'dp_max_grad_norm': '1.0', 'epochs': '3', 'lr': '0.01', 'batch_size': '64', 'checkpoint': <azure.ai.ml._restclient.v2023_02_01_preview.models._models_py3.UriFolderJobInput object at 0x0000024313971350>}, 'job_outputs': {'aggregated_output': '${{parent.outputs.aggregated_output}}'}, 'inputs': {'dp': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000024313972F10>, 'dp_target_epsilon': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000024313973E90>, 'dp_target_delta': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000024313972910>, 'dp_max_grad_norm': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000024313974490>, 'epochs': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000024313974450>, 'lr': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000024313974410>, 'batch_size': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000024313974350>, 'checkpoint': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000024313974310>}, 'outputs': {'aggregated_output': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x00000243139740D0>}, 'component': 'azureml_anonymous:743bfa4d-77d1-4c7f-beae-e73b6c881fcf', 'referenced_control_flow_node_instance_id': '54e62012-a324-41dd-a220-26ac50899726', 'kwargs': {}, 'instance_id': '29626a3d-6be2-47d1-b962-66d6d37be7f1', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'settings': None}), 'dowhile': <azure.ai.ml.entities._builders.do_while.DoWhile object at 0x0000024313973210>}, 'job_types': {'pipeline': 1, 'do_while': 1}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 1, 'CLASS': 1}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'clever_atemoya_nd1q37kc0b', 'description': '\\n            Creates a scatter-gather graph by executing the scatter_gather_iteration_body\\n            function in a do-while loop. The loop terminates when the user-supplied\\n            termination condition is met.\\n            ', 'tags': {}, 'properties': {'azureml.telemetry.attribute': 'scatter-gather', 'mlflow.source.git.repoURL': 'https://github.com/Azure-Samples/azure-ml-federated-learning.git', 'mlflow.source.git.branch': 'gargamit/fl_sdk_contract', 'mlflow.source.git.commit': 'bed00852337f30b8059da6aec17cfceb4f4efd89', 'azureml.git.dirty': 'True', 'azureml.DevPlatv2': 'true', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'True', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.defaultDataStoreName': 'workspaceblobstore', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': True, 'id': '/subscriptions/48bbc269-ce89-4f6f-9a12-c6f91fcb772d/resourceGroups/thopo-owner-fldev-rg/providers/Microsoft.MachineLearningServices/workspaces/aml-thopo-fl40/jobs/clever_atemoya_nd1q37kc0b', 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\Amit Garg\\\\OneDrive - Microsoft\\\\Documents\\\\azure-samples-main-repo\\\\azure-ml-federated-learning\\\\examples\\\\pipelines\\\\fl_cross_silo_scatter_gather', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x00000243139760D0>, 'serialize': <msrest.serialization.Serializer object at 0x000002431398AB50>, 'display_name': 'Scatter gather graph', 'experiment_name': 'example_fl_pipeline', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/48bbc269-ce89-4f6f-9a12-c6f91fcb772d/resourceGroups/thopo-owner-fldev-rg/providers/Microsoft.MachineLearningServices/workspaces/aml-thopo-fl40?', 'job_service_type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/clever_atemoya_nd1q37kc0b?wsid=/subscriptions/48bbc269-ce89-4f6f-9a12-c6f91fcb772d/resourcegroups/thopo-owner-fldev-rg/workspaces/aml-thopo-fl40&tid=72f988bf-86f1-41af-91ab-2d7cd011db47', 'job_service_type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "import azure.ai.ml.dsl._fl_scatter_gather_node as fl\n",
    "from azure.ai.ml.entities._credentials import UserIdentityConfiguration\n",
    "\n",
    "\n",
    "# iterations = 2 # arbitrary value set for example\n",
    "# @pipeline(default_compute=YAML_CONFIG.orchestrator.compute)\n",
    "# def fl_pipeline():\n",
    "fl_node = fl.fl_scatter_gather(\n",
    "    silo_configs=silo_list,\n",
    "    silo_component=silo_scatter_subgraph,\n",
    "    aggregation_component=aggregate_component,\n",
    "    aggregation_compute=YAML_CONFIG.orchestrator.compute,\n",
    "    aggregation_datastore=YAML_CONFIG.orchestrator.datastore,\n",
    "    shared_silo_kwargs=silo_kwargs,\n",
    "    aggregation_kwargs=agg_kwargs,\n",
    "    silo_to_aggregation_argument_map=silo_to_aggregation_argument_map,\n",
    "    aggregation_to_silo_argument_map=aggregation_to_silo_argument_map,\n",
    "    max_iterations=YAML_CONFIG.iterations, \n",
    ")\n",
    "    # NOTE: If you wish to examine the client-side subgraph, uncomment the following line (warning: large output)\n",
    "    # print(fl_node.subgraph)\n",
    "\n",
    "# fl_pipeline_job = fl_pipeline()\n",
    "# fl_pipeline_job.identity = UserIdentityConfiguration()\n",
    "fl_pipeline_job = ml_client.jobs.create_or_update(fl_node.scatter_gather_graph, experiment_name=\"example_fl_pipeline\")\n",
    "fl_pipeline_job"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_sdk_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fd1569a76b7ca3eba0da9e0ecbed98cdf9c274b2525be53134564ec5983f107"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
