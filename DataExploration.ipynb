{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>StateCode</th>\n",
       "      <th>Region</th>\n",
       "      <th>Division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "      <td>West</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>South</td>\n",
       "      <td>East South Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "      <td>South</td>\n",
       "      <td>West South Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "      <td>West</td>\n",
       "      <td>Mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>West</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State StateCode Region            Division\n",
       "0      Alaska        AK   West             Pacific\n",
       "1     Alabama        AL  South  East South Central\n",
       "2    Arkansas        AR  South  West South Central\n",
       "3     Arizona        AZ   West            Mountain\n",
       "4  California        CA   West             Pacific"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_states_regions = pd.read_csv(\"./examples/components/CreditCardFraud/preprocessing/us_regions.csv\")\n",
    "states_regions = {row.StateCode: row.Region for row in df_states_regions.itertuples()}\n",
    "\n",
    "df_states_regions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['West', 'South', 'Northeast', 'Midwest']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_states_regions['Region'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_props = ['amt','cc_num', 'merch_lat', 'merch_long', 'category', 'gender', 'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'dob', 'trans_date_trans_time', 'is_fraud']\n",
    "categorical = ['category', 'gender', 'region', 'state', 'job']\n",
    "datetimes = ['dob', 'trans_date_trans_time']\n",
    "normalize = ['dob', 'age']\n",
    "\n",
    "encoders = {}\n",
    "\n",
    "def basic_transforms(df):\n",
    "    # Just so we are always aware of all available columns\n",
    "    print(df.columns)\n",
    "\n",
    "    # Filter only useful columns\n",
    "    df = df[useful_props]\n",
    "\n",
    "    # df[\"full_name\"] = df[\"first\"] + \" \" + df[\"last\"]\n",
    "    df.loc[:, 'region'] = df['state'].map(states_regions)\n",
    "    df.loc[:, 'age'] = (pd.Timestamp.now() - pd.to_datetime(df['dob'])) // pd.Timedelta('1y')\n",
    "    for column in categorical:\n",
    "        if column not in encoders:\n",
    "            print(f\"Creating encoder for column: {column}\")\n",
    "            # Simply set all zeros if the category is unseen\n",
    "            encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "            encoder.fit(df[column].values.reshape(-1,1))\n",
    "            encoders[column] = encoder\n",
    "\n",
    "        encoder = encoders.get(column)\n",
    "        encoded_data = encoder.transform(df[column].values.reshape(-1,1)).toarray()\n",
    "        encoded_df = pd.DataFrame(encoded_data, columns = [column + \"_\" + '_'.join(x.split('_')[1:]) for x in encoder.get_feature_names()])\n",
    "        encoded_df.index = df.index\n",
    "        df = df.join(encoded_df).drop(column, axis=1)\n",
    "\n",
    "    for column in datetimes:\n",
    "        df.loc[:, column] = pd.to_datetime(df[column]).view('int64')\n",
    "    for column in normalize:\n",
    "        df.loc[:, column] = (df[column] - df[column].min())/(df[column].max() - df[column].min())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt',\n",
      "       'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat',\n",
      "       'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat',\n",
      "       'merch_long', 'is_fraud'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\damajercak\\.conda\\envs\\fl\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "c:\\Users\\damajercak\\.conda\\envs\\fl\\lib\\site-packages\\pandas\\core\\indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating encoder for column: category\n",
      "Creating encoder for column: gender\n",
      "Creating encoder for column: region\n",
      "Creating encoder for column: state\n",
      "Creating encoder for column: job\n",
      "Index(['trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt',\n",
      "       'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat',\n",
      "       'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat',\n",
      "       'merch_long', 'is_fraud'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\damajercak\\.conda\\envs\\fl\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "c:\\Users\\damajercak\\.conda\\envs\\fl\\lib\\site-packages\\pandas\\core\\indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['amt', 'cc_num', 'merch_lat', 'merch_long', 'zip', 'lat', 'long',\n",
      "       'city_pop', 'dob', 'trans_date_trans_time',\n",
      "       ...\n",
      "       'job_Visual merchandiser', 'job_Volunteer coordinator',\n",
      "       'job_Warden/ranger', 'job_Warehouse manager',\n",
      "       'job_Waste management officer', 'job_Water engineer',\n",
      "       'job_Water quality scientist', 'job_Web designer',\n",
      "       'job_Wellsite geologist', 'job_Writer'],\n",
      "      dtype='object', length=577)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>...</th>\n",
       "      <th>job_Visual merchandiser</th>\n",
       "      <th>job_Volunteer coordinator</th>\n",
       "      <th>job_Warden/ranger</th>\n",
       "      <th>job_Warehouse manager</th>\n",
       "      <th>job_Waste management officer</th>\n",
       "      <th>job_Water engineer</th>\n",
       "      <th>job_Water quality scientist</th>\n",
       "      <th>job_Web designer</th>\n",
       "      <th>job_Wellsite geologist</th>\n",
       "      <th>job_Writer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.97</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>28654</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>0.789499</td>\n",
       "      <td>1546300818000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.23</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>99160</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>0.668418</td>\n",
       "      <td>1546300844000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220.11</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>83252</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>0.463819</td>\n",
       "      <td>1546300851000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.00</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>59632</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>0.525878</td>\n",
       "      <td>1546300876000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.96</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>24433</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>0.765208</td>\n",
       "      <td>1546300986000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 577 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      amt            cc_num  merch_lat  merch_long    zip      lat      long  \\\n",
       "0    4.97  2703186189652095  36.011293  -82.048315  28654  36.0788  -81.1781   \n",
       "1  107.23      630423337322  49.159047 -118.186462  99160  48.8878 -118.2105   \n",
       "2  220.11    38859492057661  43.150704 -112.154481  83252  42.1808 -112.2620   \n",
       "3   45.00  3534093764340240  47.034331 -112.561071  59632  46.2306 -112.1138   \n",
       "4   41.96   375534208663984  38.674999  -78.632459  24433  38.4207  -79.4629   \n",
       "\n",
       "   city_pop       dob  trans_date_trans_time  ...  job_Visual merchandiser  \\\n",
       "0      3495  0.789499    1546300818000000000  ...                      0.0   \n",
       "1       149  0.668418    1546300844000000000  ...                      0.0   \n",
       "2      4154  0.463819    1546300851000000000  ...                      0.0   \n",
       "3      1939  0.525878    1546300876000000000  ...                      0.0   \n",
       "4        99  0.765208    1546300986000000000  ...                      0.0   \n",
       "\n",
       "   job_Volunteer coordinator  job_Warden/ranger  job_Warehouse manager  \\\n",
       "0                        0.0                0.0                    0.0   \n",
       "1                        0.0                0.0                    0.0   \n",
       "2                        0.0                0.0                    0.0   \n",
       "3                        0.0                0.0                    0.0   \n",
       "4                        0.0                0.0                    0.0   \n",
       "\n",
       "   job_Waste management officer  job_Water engineer  \\\n",
       "0                           0.0                 0.0   \n",
       "1                           0.0                 0.0   \n",
       "2                           0.0                 0.0   \n",
       "3                           0.0                 0.0   \n",
       "4                           0.0                 0.0   \n",
       "\n",
       "   job_Water quality scientist  job_Web designer  job_Wellsite geologist  \\\n",
       "0                          0.0               0.0                     0.0   \n",
       "1                          0.0               0.0                     0.0   \n",
       "2                          0.0               0.0                     0.0   \n",
       "3                          0.0               0.0                     0.0   \n",
       "4                          0.0               0.0                     0.0   \n",
       "\n",
       "   job_Writer  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 577 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"fraudTrain.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"fraudTest.csv\", index_col=0)\n",
    "\n",
    "df_train = basic_transforms(df_train)\n",
    "df_test = basic_transforms(df_test)\n",
    "\n",
    "print(df_train.columns)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['amt', 'cc_num', 'merch_lat', 'merch_long', 'zip', 'lat', 'long',\n",
      "       'city_pop', 'dob', 'trans_date_trans_time',\n",
      "       ...\n",
      "       'job_Visual merchandiser', 'job_Volunteer coordinator',\n",
      "       'job_Warden/ranger', 'job_Warehouse manager',\n",
      "       'job_Waste management officer', 'job_Water engineer',\n",
      "       'job_Water quality scientist', 'job_Web designer',\n",
      "       'job_Wellsite geologist', 'job_Writer'],\n",
      "      dtype='object', length=577)\n",
      "Index(['amt', 'cc_num', 'merch_lat', 'merch_long', 'zip', 'lat', 'long',\n",
      "       'city_pop', 'dob', 'trans_date_trans_time',\n",
      "       ...\n",
      "       'job_Visual merchandiser', 'job_Volunteer coordinator',\n",
      "       'job_Warden/ranger', 'job_Warehouse manager',\n",
      "       'job_Waste management officer', 'job_Water engineer',\n",
      "       'job_Water quality scientist', 'job_Web designer',\n",
      "       'job_Wellsite geologist', 'job_Writer'],\n",
      "      dtype='object', length=577)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 10000\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(len(df_train.columns) - 1, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 4),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4, 1),\n",
    "    nn.Sigmoid()\n",
    ").to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-7)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"FraudDataset Dataset - combination of features and labels\n",
    "\n",
    "    Args:\n",
    "        feature: Transaction detail tensors\n",
    "        target: Tensor of labels corresponding to features\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature, target=None):\n",
    "        self.X = feature\n",
    "        self.Y = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.Y is None:\n",
    "            return [self.X[idx]]\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FraudDataset(torch.tensor(df_train.loc[:, df_train.columns != \"is_fraud\"].values, dtype=torch.float), torch.tensor(df_train.loc[:, \"is_fraud\"].values, dtype=torch.float))\n",
    "test_dataset = FraudDataset(torch.tensor(df_test.loc[:, df_test.columns != \"is_fraud\"].values, dtype=torch.float), torch.tensor(df_test.loc[:, \"is_fraud\"].values, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Epoch: 0/100, Iteration: 10/130, Phase: train, Loss: 9.899999767541885e-05, Accuracy: 0.9901\n",
      "Epoch: 0/100, Iteration: 20/130, Phase: train, Loss: 6.549999773502351e-05, Accuracy: 0.9934499999999999\n",
      "Epoch: 0/100, Iteration: 30/130, Phase: train, Loss: 6.099999725818634e-05, Accuracy: 0.9939\n",
      "Epoch: 0/100, Iteration: 40/130, Phase: train, Loss: 3.9899999424815176e-05, Accuracy: 0.9960099999999998\n",
      "Epoch: 0/100, Iteration: 50/130, Phase: train, Loss: 3.869999848306179e-05, Accuracy: 0.99613\n",
      "Epoch: 0/100, Iteration: 60/130, Phase: train, Loss: 4.769999884068967e-05, Accuracy: 0.99523\n",
      "Epoch: 0/100, Iteration: 70/130, Phase: train, Loss: 6.599999845027924e-05, Accuracy: 0.9934\n",
      "Epoch: 0/100, Iteration: 80/130, Phase: train, Loss: 5.1199998557567595e-05, Accuracy: 0.9948799999999999\n",
      "Epoch: 0/100, Iteration: 90/130, Phase: train, Loss: 3.999999925494195e-05, Accuracy: 0.9960000000000001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [81], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m dataloader \u001b[39m=\u001b[39m train_dataloader \u001b[39mif\u001b[39;00m phase \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m test_dataloader\n\u001b[0;32m     10\u001b[0m net\u001b[39m.\u001b[39mtrain() \u001b[39mif\u001b[39;00m phase \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m\u001b[39melse\u001b[39;00m net\u001b[39m.\u001b[39meval()\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfor\u001b[39;00m j, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m     13\u001b[0m     i \u001b[39m=\u001b[39m j \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     14\u001b[0m     data, labels \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device), batch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\damajercak\\.conda\\envs\\fl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\damajercak\\.conda\\envs\\fl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\damajercak\\.conda\\envs\\fl\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\damajercak\\.conda\\envs\\fl\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32mc:\\Users\\damajercak\\.conda\\envs\\fl\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\damajercak\\.conda\\envs\\fl\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\damajercak\\.conda\\envs\\fl\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 120\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[0;32m    122\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    123\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\damajercak\\.conda\\envs\\fl\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:163\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    162\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "log_step = 10\n",
    "running_loss = 0.0\n",
    "running_acc = 0.0\n",
    "for epoch in range(100):\n",
    "    for phase in ['train', 'test']:\n",
    "        print(phase)\n",
    "        dataloader = train_dataloader if phase == 'train' else test_dataloader\n",
    "\n",
    "        net.train() if phase == 'train'else net.eval()\n",
    "\n",
    "        for j, batch in enumerate(dataloader):\n",
    "            i = j + 1\n",
    "            data, labels = batch[0].to(device), batch[1].to(device)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            predictions = net(data)\n",
    "            accuracy = float((predictions == labels.reshape(-1,1)).detach().cpu().numpy().sum()) / labels.shape[0]\n",
    "            running_acc += accuracy\n",
    "\n",
    "            if phase == 'train':\n",
    "                cost = criterion(predictions, labels.reshape(-1,1))\n",
    "                cost.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += cost.cpu().detach().numpy() / data.size()[0]\n",
    "                if i != 0 and i % log_step == 0:\n",
    "                    training_loss = running_loss / log_step\n",
    "                    training_acc = running_acc / log_step\n",
    "                    print(\n",
    "                        f\"Epoch: {epoch}/{epochs}, Iteration: {i}/{len(dataloader)}, Phase: {phase}, Loss: {training_loss}, Accuracy: {training_acc}\"\n",
    "                    )\n",
    "\n",
    "                    running_loss = 0.0\n",
    "                    running_acc = 0.0\n",
    "            else:\n",
    "                if i != 0 and i % log_step == 0:\n",
    "                    training_acc = running_acc / log_step\n",
    "                    print(\n",
    "                        f\"Epoch: {epoch}/{epochs}, Iteration: {i}/{len(dataloader)}, Phase: {phase}, Accuracy: {training_acc}\"\n",
    "                    )\n",
    "\n",
    "                    running_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('fl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1077eee06993cd7cc8abd3b05a0a6bc1885796a9ebf8ac85522f7723ef2872fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
