{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_states_regions = pd.read_csv(\"./examples/components/CreditCardFraud/preprocessing/us_regions.csv\")\n",
    "states_regions = {row.StateCode: row.Region for row in df_states_regions.itertuples()}\n",
    "\n",
    "df_states_regions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_states_regions['Region'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "useful_props = [\n",
    "    \"amt\",\n",
    "    \"age\",\n",
    "    # \"cc_num\",\n",
    "    \"merch_lat\",\n",
    "    \"merch_long\",\n",
    "    \"category\",\n",
    "    \"region\",\n",
    "    \"gender\",\n",
    "    \"state\",\n",
    "    \"zip\",\n",
    "    \"lat\",\n",
    "    \"long\",\n",
    "    \"city_pop\",\n",
    "    \"job\",\n",
    "    # \"dob\",\n",
    "    \"trans_date_trans_time\",\n",
    "    \"is_fraud\",\n",
    "]\n",
    "categorical = [\"category\", \"region\", \"gender\", \"state\", \"job\"]\n",
    "datetimes = [\"trans_date_trans_time\"]\n",
    "normalize = [\"age\", \"merch_lat\", \"merch_long\", \"lat\", \"long\", \"city_pop\", \"trans_date_trans_time\", \"amt\"]\n",
    "\n",
    "ENCODERS = {}\n",
    "SCALERS = {}\n",
    "\n",
    "def basic_transforms(df):\n",
    "    # Just so we are always aware of all available columns\n",
    "    print(df.columns)\n",
    "\n",
    "    # Filter only useful columns\n",
    "    df.loc[:, 'age'] = (pd.Timestamp.now() - pd.to_datetime(df['dob'])) // pd.Timedelta('1y')\n",
    "\n",
    "    df = df[useful_props]\n",
    "    for column in categorical:\n",
    "        if column not in ENCODERS:\n",
    "            print(f\"Creating encoder for column: {column}\")\n",
    "            # Simply set all zeros if the category is unseen\n",
    "            encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "            encoder.fit(df[column].values.reshape(-1,1))\n",
    "            ENCODERS[column] = encoder\n",
    "\n",
    "        encoder = ENCODERS.get(column)\n",
    "        encoded_data = encoder.transform(df[column].values.reshape(-1,1)).toarray()\n",
    "        encoded_df = pd.DataFrame(encoded_data, columns = [column + \"_\" + \"_\".join(x.split(\"_\")[1:]) for x in encoder.get_feature_names()])\n",
    "        encoded_df.index = df.index\n",
    "        df = df.join(encoded_df).drop(column, axis=1)\n",
    "\n",
    "    for column in datetimes:\n",
    "        df.loc[:, column] = pd.to_datetime(df[column]).view('int64')\n",
    "    for column in normalize:\n",
    "        if column not in SCALERS:\n",
    "            print(f\"Creating encoder for column: {column}\")\n",
    "            # Simply set all zeros if the category is unseen\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(df[column].values.reshape(-1,1))\n",
    "            SCALERS[column] = scaler\n",
    "\n",
    "        scaler = SCALERS.get(column)\n",
    "        # df.loc[:, column] = scaler.transform(df[column].values.reshape(-1,1))\n",
    "        df[column] = scaler.transform(df[column].values.reshape(-1,1))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"fraudTrain.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"fraudTest.csv\", index_col=0)\n",
    "\n",
    "df_train.loc[:, 'region'] = df_train['state'].map(states_regions)\n",
    "df_test.loc[:, 'region'] = df_test['state'].map(states_regions)\n",
    "\n",
    "df_train = df_train[df_train[\"region\"].str.match(\".*est.*\")]\n",
    "df_test = df_test[df_test[\"region\"].str.match(\".*est.*\")]\n",
    "\n",
    "df_train = basic_transforms(df_train)\n",
    "df_test = basic_transforms(df_test)\n",
    "\n",
    "print(df_train.columns)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 10000\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(len(df_train.columns) - 1, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 4),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4, 1),\n",
    "    nn.Sigmoid()\n",
    ").to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-5)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"FraudDataset Dataset - combination of features and labels\n",
    "\n",
    "    Args:\n",
    "        feature: Transaction detail tensors\n",
    "        target: Tensor of labels corresponding to features\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature, target=None):\n",
    "        self.X = feature\n",
    "        self.Y = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.Y is None:\n",
    "            return [self.X[idx]]\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FraudDataset(torch.tensor(df_train.loc[:, df_train.columns != \"is_fraud\"].values, dtype=torch.float), torch.tensor(df_train.loc[:, \"is_fraud\"].values, dtype=int))\n",
    "test_dataset = FraudDataset(torch.tensor(df_test.loc[:, df_test.columns != \"is_fraud\"].values, dtype=torch.float), torch.tensor(df_test.loc[:, \"is_fraud\"].values, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import precision_recall, accuracy\n",
    "\n",
    "epochs = 5\n",
    "log_step = 10\n",
    "running_loss = 0.0\n",
    "running_acc = 0.0\n",
    "running_rec = 0.0\n",
    "running_prec = 0.0\n",
    "for epoch in range(epochs):\n",
    "    for phase in ['train', 'test']:\n",
    "        print(phase)\n",
    "        dataloader = train_dataloader if phase == 'train' else test_dataloader\n",
    "\n",
    "        net.train() if phase == 'train'else net.eval()\n",
    "\n",
    "        for j, batch in enumerate(dataloader):\n",
    "            i = j + 1\n",
    "            data, labels = batch[0].to(device), batch[1].to(device)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            predictions = net(data)\n",
    "            # accuracy = float((predictions == labels.reshape(-1,1)).detach().cpu().numpy().sum()) / labels.shape[0]\n",
    "            running_acc += accuracy(predictions, labels)\n",
    "            precrec = precision_recall(predictions, labels)\n",
    "            running_prec += precrec[0]\n",
    "            running_rec += precrec[1]\n",
    "\n",
    "            if phase == 'train':\n",
    "                cost = criterion(predictions, labels.reshape(-1,1).type(torch.float))\n",
    "                cost.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += cost.cpu().detach().numpy() / data.size()[0]\n",
    "                if i != 0 and i % log_step == 0:\n",
    "                    training_loss = running_loss / log_step\n",
    "                    training_acc = running_acc / log_step\n",
    "                    training_prec = running_prec / log_step\n",
    "                    training_rec = running_rec / log_step\n",
    "                    print(\n",
    "                        f\"Epoch: {epoch}/{epochs}, Iteration: {i}/{len(dataloader)}, Phase: {phase}, Loss: {training_loss}, Accuracy: {training_acc}, Precision: {training_prec}, Recall: {training_rec}\"\n",
    "                    )\n",
    "\n",
    "                    running_loss = 0.0\n",
    "                    running_acc = 0.0\n",
    "                    running_prec = 0.0\n",
    "                    running_rec = 0.0\n",
    "            else:\n",
    "                if i != 0 and i % log_step == 0:\n",
    "                    training_acc = running_acc / log_step\n",
    "                    training_prec = running_prec / log_step\n",
    "                    training_rec = running_rec / log_step\n",
    "                    print(\n",
    "                        f\"Epoch: {epoch}/{epochs}, Iteration: {i}/{len(dataloader)}, Phase: {phase}, Accuracy: {training_acc}, Precision: {training_prec}, Recall: {training_rec}\"\n",
    "                    )\n",
    "\n",
    "                    running_acc = 0.0\n",
    "                    running_prec = 0.0\n",
    "                    running_rec = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('fl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1077eee06993cd7cc8abd3b05a0a6bc1885796a9ebf8ac85522f7723ef2872fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
